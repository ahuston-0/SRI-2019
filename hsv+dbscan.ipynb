{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "import multiprocessing\n",
    "import cv2 as cv\n",
    "import rospy\n",
    "import cv_bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is the iterative function that reads each image,\n",
    "# transforms them, and writes them to a directory. The only\n",
    "# thing that the user needs to change is the file name and\n",
    "# directory in the inputs for imread and imwrite\n",
    "\n",
    "def read(x):\n",
    "    img2 = cv.imread('images/left' + str(x).zfill(4) + '.jpg',1)\n",
    "    result1 = transform(img2)\n",
    "    cv.imwrite('output_images/test2/test' + str(x).zfill(4) + '.jpg', result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this function before you run the cell below.\n",
    "# You don't need to change anything to this cell.\n",
    "x = 0\n",
    "read(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once a color image has been read, it passes through the \n",
    "# transform function. The transform function has two parts:\n",
    "# pre-processing also known as pp which filters the image based\n",
    "# of certain values in the hue, saturation, and value (hsv) \n",
    "# colorspace and the dbscan which clusters the processed image\n",
    "# and classifies the clusters as either a buoy, a green buoy,\n",
    "# a red buoy, or noise. No changes are needed.\n",
    "\n",
    "def transform(img):\n",
    "    image = pp(img)\n",
    "    img2 = dbscan(image, img)\n",
    "    return img2\n",
    "\n",
    "# The first function in transform is pp or preprocessing. The \n",
    "# first line truncates the lower half of the image. The reason\n",
    "# this is because the plantoons from the wamv are always \n",
    "# blocking the camera vision and become noisy data. The\n",
    "# function changes the image to the HSV colorspace and \n",
    "# filters out the image. No changes are needed. It returns \n",
    "# the filtered image in the BGR colorspace.The input is the\n",
    "# color image.\n",
    "\n",
    "def pp(image):\n",
    "    image = np.array(image[0:800][0:515])\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
    "    image[np.logical_not(np.logical_or(np.logical_and(image[:,:,0] > 70, image[:,:,0] < 90),np.logical_or(image[:,:,0] >= 170, image[:,:,0] < 10)))] = [0,0,0]\n",
    "    image = cv.cvtColor(image,cv.COLOR_HSV2BGR)\n",
    "    return(image)\n",
    "\n",
    "# The second function in transform is dbscan. The inputs are \n",
    "# the filtered colored image and the original color image\n",
    "# read from the imread statement. The output is the original\n",
    "# image.This is the end of this classification algorithm.\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def dbscan(image, original): \n",
    "\n",
    "# Part 1: Thresholding the image\n",
    "##########################################################\n",
    "# The reason we threshold the image before applying DBSCAN to \n",
    "# the points is because DBSCAN is a computational demanding \n",
    "# function. This part takes the filtered image, makes a \n",
    "# copy of it, and converts it into a grayscale image. The gray-\n",
    "# scale image is thresholded at a value of 10. 0 is black and\n",
    "# 255 is white. This takes the ~400,000 matrix points and \n",
    "# leaves only ~10,000 nonzero matrix points. \n",
    "\n",
    "    img = image.copy()\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret,thresh1 = cv.threshold(img,10,255,cv.THRESH_BINARY)\n",
    "\n",
    "# After thresholding the image, we pull out those nonzero\n",
    "# points and assign it to the nonzero array variable. This\n",
    "# array has dimensions of n rows and 2 columns. The first \n",
    "# column is the y coordinate and the second column is the x\n",
    "# coordinate. These two arrays would be combined by \n",
    "# np.column_stack which merges the two arrays at their columns.\n",
    "\n",
    "    nonzero = np.nonzero(thresh1)\n",
    "\n",
    "    yp = np.array(nonzero[0])\n",
    "    xp = np.array(nonzero[1])\n",
    "\n",
    "\n",
    "    X=np.column_stack((xp,yp))\n",
    "#########################################################\n",
    "  \n",
    "# Creating the BDSCAN object and Sorting Array with Labels\n",
    "#########################################################    \n",
    "# After thresholding the filtered image and creating an\n",
    "# array of nonzero coordinates, this algorithm applies a\n",
    "# clustering algorithm that filters the image based off the\n",
    "# array X. If X is empty, this function ends and output is \n",
    "# the original input. The first line creates the DBSCAN\n",
    "# object with an epsilon of 3 and minimum samples of 20. \n",
    "# Eps refers to the size of the neighborhood and the \n",
    "# min_samples refers to the minimum number of samples required\n",
    "# for that neighborhood to be considered a cluster. The user\n",
    "# is free to change the two values for eps and min_samples. The\n",
    "# .fit(X) applies the matrix points to the DBSCAN object.\n",
    "# One of the parameters of the db scan object are the labels.\n",
    "# This is invoked by the line labels = db.labels. This creates\n",
    "# an array of labels that assigns a number to the image index.\n",
    "# n clusters have labels that start at 0 and end with n-1.For \n",
    "# example, if an image has four clusters, the labels would\n",
    "# include 0,1,2, and 3. -1 is dedicated for noise. \n",
    "\n",
    "    if (len(X) > 0):\n",
    "        db = DBSCAN(eps=3, min_samples=20).fit(X)\n",
    "        labels = db.labels_\n",
    "\n",
    "# The array variable combines the x and y coordinates and the \n",
    "# labels in a single array aligned by column. The array is\n",
    "# sorted with the sort variable with the values in the third\n",
    "# column or the labels. For example, an image with four\n",
    "# clusters and noise would be labeled in order from (-1,0,1,2,3).\n",
    "# The while loop iterates from the beginning of the sorted loop\n",
    "# and deletes every instance of -1 or until the list is empty.\n",
    "# This while loop is needed because the noise data is\n",
    "# irrelevant to the cluster algorithm and the user does not \n",
    "# know how much noise there is in the image. The image could \n",
    "# have no noise or it could all be noise. The output of this\n",
    "# section is an array with coordinates sorted together in \n",
    "# clusters.\n",
    "\n",
    "        array = zip(xp,yp,labels)\n",
    "        sort = sorted(list(array), key=lambda x: x[2])\n",
    "        \n",
    "        x = 0\n",
    "        while (len(sort) > 0 and sort[x][2] == -1):\n",
    "            del sort[x]\n",
    "#########################################################\n",
    "\n",
    "# Iterating through and classifying each cluster\n",
    "#########################################################\n",
    "# After iterating through sort, the program is either left with\n",
    "# an empty array or an array of coordinates sorted and grouped\n",
    "# by each cluster. The user needs the number of clusters. The \n",
    "# next three lines in the big if block does this. unique_labels\n",
    "# sorts the set of labels and removes -1 if present. The next \n",
    "# two lines creates a copy of the sort array and removes the \n",
    "# labels column from the array.\n",
    "\n",
    "        if (len(sort) > 0):\n",
    "            unique_labels = sorted(set(labels))\n",
    "            if (unique_labels[0] == -1):\n",
    "                unique_labels.remove(-1)\n",
    "            points = sort.copy()\n",
    "            points = np.delete(points,2,1)\n",
    "\n",
    "# The program assigns three variables. The first one i iterates\n",
    "# through sort and compare its label value to x for each \n",
    "# iteration until the very end of the sort array. The second\n",
    "# x refers to the cluster that the program is currently class-\n",
    "# ifying. It starts with 0 and continues classifying until it \n",
    "# has classified all clusters. The third variable is l and this\n",
    "# array becomes all the points within a cluster. Every time the \n",
    "# variable i iterates through sort and is equal to the value of\n",
    "# the current cluster x, the coordinates are appended to the \n",
    "# array l. Since this array is sorted, the first time the x \n",
    "# variable equals a different value- the cluster has been \n",
    "# accounted for. This array of l contains all the points within\n",
    "# the cluster. This array and the filtered image gets passed\n",
    "# through the color function. The result of the color function\n",
    "# gets passed through the rectangle function with the array,\n",
    "# filtered image, and original image. The x variable is \n",
    "# incremented for the next cluster and the l array is set equal \n",
    "# to zero. Once the while loop has iterated through all \n",
    "# clusters, the result of the rectangle function is set to the \n",
    "# original image and the original image is returned to the \n",
    "# transform function which is returned to the read function \n",
    "# which writes the image.\n",
    " \n",
    "            i = 0\n",
    "            x = 0\n",
    "            l = []\n",
    "\n",
    "            while (x < len(unique_labels)):\n",
    "                if (i < len(sort) and sort[i][2] == x):\n",
    "                    l.append(points[i])\n",
    "                    i+=1\n",
    "                else:\n",
    "                    x+=1\n",
    "                    clr = color(np.array(l),image)\n",
    "                    tb = rectangle(np.array(l),clr,image,original)\n",
    "                    l = []\n",
    "            original = tb   \n",
    "    return original\n",
    "\n",
    "############################################################\n",
    "\n",
    "# For the color function, the points of the cluster and the \n",
    "# filtered image are passed through. In this function, the \n",
    "# average red, green, and blue pixel values are calculated\n",
    "# from the image inside of the cluster. If the average value\n",
    "# fits within a certain range, the string 'red' or 'green' is \n",
    "# returned. Otherwise, the function returns the string 'none'\n",
    "# The user is free to change the range of the BGR values that\n",
    "# determine whether the buoy is red or green.\n",
    "\n",
    "def color(mat,image):\n",
    "    sumred = 0\n",
    "    sumgrn = 0\n",
    "    sumblu = 0\n",
    "    for x in range(len(mat)):\n",
    "        sumred += image [mat[x][1]] [mat[x][0]] [2]\n",
    "        sumgrn += image [mat[x][1]] [mat[x][0]] [1]\n",
    "        sumblu += image [mat[x][1]] [mat[x][0]] [0]\n",
    "    if ((sumred/len(mat)) > 80 and (sumred/len(mat)) < 180 and (sumgrn/len(mat)) > 30 and (sumgrn/len(mat)) < 115  and (sumblu/len(mat)) > 30 and (sumblu/len(mat)) < 110):\n",
    "        return 'red'\n",
    "    if ((sumred/len(mat)) > 30 and (sumred/len(mat)) < 80 and (sumgrn/len(mat)) > 60 and (sumgrn/len(mat)) < 180  and (sumblu/len(mat)) > 50 and (sumblu/len(mat)) < 130):\n",
    "        return 'green'\n",
    "    else:\n",
    "        return 'none'\n",
    "    \n",
    "# The rectangle function's parameters are the array of coordinates\n",
    "# of the cluster, the color of the cluster, the filtered image,\n",
    "# and the original image. The boundingRect function applies\n",
    "# a non-rotated rectangle to the image points and returns four\n",
    "# values in an array, the x and y coordinates of the leftmost\n",
    "# corner and the width and height. These values are converted\n",
    "# to ints. The font is set to Hershey Simple for the text and\n",
    "# the tag is set to zero. The tag is useful in the classifica-\n",
    "# tion of the buoy. The first classification of the buoy is \n",
    "# the proportion of the width and height. If the height is\n",
    "# between 1.5 times the width and 3.5 times the width, the\n",
    "# cluster is considered a buoy. If the cluster is given a \n",
    "# 'red' or 'green' color, it would be classified as a 'red buoy'\n",
    "# or 'green buoy' respectively. Otherwise, it would simply be\n",
    "# classified as a buoy. If any of these three options occur, \n",
    "# the tag is set to 1. If the height is not in that range\n",
    "# mentioned above and the color is 'none', the cluster is\n",
    "# classified as noise. The last function rectangle makes a \n",
    "# rectangle over the original image. The original image is sent\n",
    "# back to the DBSCAN function.\n",
    "\n",
    "def rectangle(mat,color,image,original):\n",
    "    rect = cv.boundingRect(mat)\n",
    "    height = rect[3]\n",
    "    width = rect[2]\n",
    "    x = rect[0]\n",
    "    x = np.int0(x)\n",
    "    y = rect[1] \n",
    "    y = np.int0(y)\n",
    "    font = cv.FONT_HERSHEY_SIMPLEX\n",
    "    tag = 0\n",
    "    if (1.5*width < height and 3.5*width > height):\n",
    "        if(color =='green'):\n",
    "            tag = 1\n",
    "            cv.putText(original,color+' buoy',(np.int0(x-width/2),np.int0(y-height/2.5)), font, 0.5,(255,255,255),2,cv.LINE_AA)\n",
    "        elif(color =='red'):\n",
    "            tag = 1\n",
    "            cv.putText(original,color+' buoy',(np.int0(x-width/2),np.int0(y-height/2.5)), font, 0.5,(255,255,255),2,cv.LINE_AA)\n",
    "        else:\n",
    "            tag = 1\n",
    "            cv.putText(original,'buoy',(np.int0(x-width/2),np.int0(y-height/2.5)), font, 0.5,(255,255,255),2,cv.LINE_AA)     \n",
    "    if(color == 'none' and tag == 0):\n",
    "        cv.putText(original,'noise',(np.int0(x-width/2),np.int0(y-height/2.5)), font, 0.5,(255,255,255),2,cv.LINE_AA)\n",
    "    cv.rectangle(original,(x,y),(x+width,y+height),(255,0,255),2)\n",
    "    return original\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That took {} seconds 13.822510719299316\n"
     ]
    }
   ],
   "source": [
    "# When the file is run as the main program, this process will\n",
    "# run. The only thing that the user needs to change in this\n",
    "# program is the value of r. \n",
    "#\n",
    "#\n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "# The below variable is the only thing that the user needs\n",
    "# to change. The value should be equal to the total images\n",
    "# the user needs to process.\n",
    "    r = 2928\n",
    "    starttime = time.time()\n",
    "    pool = multiprocessing.Pool(multiprocessing.cpu_count())\n",
    "    \n",
    "    \n",
    "    pool.map(read,range(r),32)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    print('That took {} seconds',format(time.time() - starttime))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That took {} seconds 16.97206401824951\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "\n",
    "# This block of code is dedicated for creating an .avi video\n",
    "# file of the output_images. The required parameters for this\n",
    "# section is a single directory with all the images that you\n",
    "# would like to make into a video. The images are put into a\n",
    "# single array img_arr. Please be careful of the size of the \n",
    "# array. The larger the size, the more likely, the more likely \n",
    "# computer will break. Processing ~3000 images on an i7 with 12\n",
    "# gb of ram broke my computer. The only thing the user needs to\n",
    "# change is the pathfile to the directory and the output file\n",
    "# pathfile.\n",
    "\n",
    "img_arr = []\n",
    "starttime = time.time()\n",
    "for x in range(0,2927):\n",
    "    img = cv.imread('output_images/test2/test' + str(x).zfill(4) + '.jpg',1)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_arr.append(img)\n",
    "out = cv.VideoWriter('output_images/alice_images.avi',cv.VideoWriter_fourcc(*'DIVX'), 20, size)\n",
    "for i in range(len(img_arr)):\n",
    "    out.write(img_arr[i])\n",
    "out.release()\n",
    "print('That took {} seconds',format(time.time() - starttime))\n",
    "\n",
    "#############################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
