{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "import multiprocessing\n",
    "import os\n",
    "import rospy\n",
    "from sensor_msgs.msg import Image\n",
    "from stereo_msgs.msg import DisparityImage\n",
    "from sensor_msgs.msg import PointCloud2\n",
    "from nav_msgs.msg import OccupancyGrid as Map\n",
    "import message_filters\n",
    "import cv_bridge\n",
    "import tf\n",
    "import math\n",
    "from std_msgs.msg import String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     25,
     42,
     182,
     208
    ]
   },
   "outputs": [],
   "source": [
    "def transform(img):\n",
    "    \n",
    "    global bearings\n",
    "    global tags\n",
    "    \n",
    "# Once a color image has been read, it passes through the \n",
    "# transform function. The transform function has two parts:\n",
    "# pre-processing also known as pp which filters the image based\n",
    "# of certain values in the hue, saturation, and value (hsv) \n",
    "# colorspace and the dbscan which clusters the processed image\n",
    "# and classifies the clusters as either a buoy, a green buoy,\n",
    "# a red buoy, or noise. No changes are needed.\n",
    "    \n",
    "    start_time = time.time()\n",
    "    bridge = cv_bridge.CvBridge()\n",
    "    bearings = []\n",
    "    tags = []\n",
    "    width = img.height\n",
    "    height = img.width\n",
    "    img = bridge.imgmsg_to_cv2(img, desired_encoding=\"passthrough\")\n",
    "    img = cv.cvtColor(img, cv.COLOR_RGB2BGR)  \n",
    "\n",
    "    image = pp(img,width,height)\n",
    "    img2= dbscan(image, img)\n",
    "    return img2\n",
    "def pp(image, width, height):\n",
    "    \n",
    "# The first function in transform is pp or preprocessing. The \n",
    "# first line truncates the lower half of the image. The reason\n",
    "# this is because the plantoons from the wamv are always \n",
    "# blocking the camera vision and become noisy data. The\n",
    "# function changes the image to the HSV colorspace and \n",
    "# filters out the image. No changes are needed. It returns \n",
    "# the filtered image in the BGR colorspace.The input is the\n",
    "# color image.\n",
    "\n",
    "    image = np.array(image[0:width][0:int(height*0.65)])\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
    "    image[np.logical_not(np.logical_and(image[:,:,1] > 5,np.logical_or(np.logical_and(image[:,:,0] > 70, image[:,:,0] < 90),np.logical_or(image[:,:,0] >= 170, image[:,:,0] < 10))))] = [0,0,0]\n",
    "    image = cv.cvtColor(image,cv.COLOR_HSV2BGR)\n",
    "\n",
    "    return(image)\n",
    "def dbscan(image, original):\n",
    "    \n",
    "# The second function in transform is dbscan. The inputs are \n",
    "# the filtered colored image and the original color image\n",
    "# read from the imread statement. The output is the original\n",
    "# image.This is the end of this classification algorithm.\n",
    "\n",
    "###########################################################\n",
    "\n",
    "# Part 1: Thresholding the image\n",
    "##########################################################\n",
    "# The reason we threshold the image before applying DBSCAN to \n",
    "# the points is because DBSCAN is a computational demanding \n",
    "# function. This part takes the filtered image, makes a \n",
    "# copy of it, and converts it into a grayscale image. The gray-\n",
    "# scale image is thresholded at a value of 10. 0 is black and\n",
    "# 255 is white. This takes the ~400,000 matrix points and \n",
    "# leaves only ~10,000 nonzero matrix points. \n",
    "\n",
    "    img = image.copy()\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret,thresh1 = cv.threshold(img,10,255,cv.THRESH_BINARY)\n",
    "\n",
    "# After thresholding the image, we pull out those nonzero\n",
    "# points and assign it to the nonzero array variable. This\n",
    "# array has dimensions of n rows and 2 columns. The first \n",
    "# column is the y coordinate and the second column is the x\n",
    "# coordinate. These two arrays would be combined by \n",
    "# np.column_stack which merges the two arrays at their columns.\n",
    "\n",
    "    nonzero = np.nonzero(thresh1)\n",
    "\n",
    "    yp = np.array(nonzero[0])\n",
    "    xp = np.array(nonzero[1])\n",
    "\n",
    "\n",
    "    X=np.column_stack((xp,yp))\n",
    "#########################################################\n",
    "\n",
    "# Creating the BDSCAN object and Sorting Array with Labels\n",
    "#########################################################    \n",
    "# After thresholding the filtered image and creating an\n",
    "# array of nonzero coordinates, this algorithm applies a\n",
    "# clustering algorithm that filters the image based off the\n",
    "# array X. If X is empty, this function ends and output is \n",
    "# the original input. The first line creates the DBSCAN\n",
    "# object with an epsilon of 3 and minimum samples of 20. \n",
    "# Eps refers to the size of the neighborhood and the \n",
    "# min_samples refers to the minimum number of samples required\n",
    "# for that neighborhood to be considered a cluster. The user\n",
    "# is free to change the two values for eps and min_samples. The\n",
    "# .fit(X) applies the matrix points to the DBSCAN object.\n",
    "# One of the parameters of the db scan object are the labels.\n",
    "# This is invoked by the line labels = db.labels. This creates\n",
    "# an array of labels that assigns a number to the image index.\n",
    "# n clusters have labels that start at 0 and end with n-1.For \n",
    "# example, if an image has four clusters, the labels would\n",
    "# include 0,1,2, and 3. -1 is dedicated for noise. \n",
    "\n",
    "    if (len(X) > 0):\n",
    "        db = DBSCAN(eps=3, min_samples=10).fit(X)\n",
    "        labels = db.labels_\n",
    "\n",
    "# The array variable combines the x and y coordinates and the \n",
    "# labels in a single array aligned by column. The array is\n",
    "# sorted with the sort variable with the values in the third\n",
    "# column or the labels. For example, an image with four\n",
    "# clusters and noise would be labeled in order from (-1,0,1,2,3).\n",
    "# The while loop iterates from the beginning of the sorted loop\n",
    "# and deletes every instance of -1 or until the list is empty.\n",
    "# This while loop is needed because the noise data is\n",
    "# irrelevant to the cluster algorithm and the user does not \n",
    "# know how much noise there is in the image. The image could \n",
    "# have no noise or it could all be noise. The output of this\n",
    "# section is an array with coordinates sorted together in \n",
    "# clusters.\n",
    "\n",
    "        array = zip(xp,yp,labels)\n",
    "        sort = sorted(list(array), key=lambda x: x[2])\n",
    "\n",
    "        x = 0\n",
    "        while (len(sort) > 0 and sort[x][2] == -1):\n",
    "            del sort[x]\n",
    "#########################################################\n",
    "\n",
    "# Iterating through and classifying each cluster\n",
    "#########################################################\n",
    "# After iterating through sort, the program is either left with\n",
    "# an empty array or an array of coordinates sorted and grouped\n",
    "# by each cluster. The user needs the number of clusters. The \n",
    "# next three lines in the big if block does this. unique_labels\n",
    "# sorts the set of labels and removes -1 if present. The next \n",
    "# two lines creates a copy of the sort array and removes the \n",
    "# labels column from the array.\n",
    "\n",
    "        if (len(sort) > 0):\n",
    "            unique_labels = sorted(set(labels))\n",
    "            if (unique_labels[0] == -1):\n",
    "                unique_labels.remove(-1)\n",
    "            points = sort\n",
    "            points = np.delete(points,2,1)\n",
    "\n",
    "# The program assigns three variables. The first one i iterates\n",
    "# through sort and compare its label value to x for each \n",
    "# iteration until the very end of the sort array. The second\n",
    "# x refers to the cluster that the program is currently class-\n",
    "# ifying. It starts with 0 and continues classifying until it \n",
    "# has classified all clusters. The third variable is l and this\n",
    "# array becomes all the points within a cluster. Every time the \n",
    "# variable i iterates through sort and is equal to the value of\n",
    "# the current cluster x, the coordinates are appended to the \n",
    "# array l. Since this array is sorted, the first time the x \n",
    "# variable equals a different value- the cluster has been \n",
    "# accounted for. This array of l contains all the points within\n",
    "# the cluster. This array and the filtered image gets passed\n",
    "# through the color function. The result of the color function\n",
    "# gets passed through the rectangle function with the array,\n",
    "# filtered image, and original image. The x variable is \n",
    "# incremented for the next cluster and the l array is set equal \n",
    "# to zero. Once the while loop has iterated through all \n",
    "# clusters, the result of the rectangle function is set to the \n",
    "# original image and the original image is returned to the \n",
    "# transform function which is returned to the read function \n",
    "# which writes the image.\n",
    "\n",
    "            i = 0\n",
    "            x = 0\n",
    "            l = []\n",
    "            while (x < len(unique_labels)):\n",
    "                if (i < len(sort) and sort[i][2] == x):\n",
    "                    l.append(points[i])\n",
    "                    i+=1\n",
    "                else:\n",
    "                    x+=1\n",
    "                    clr = color_hsv(np.array(l),image)\n",
    "                    tb = rectangle(np.array(l),clr,image,original)\n",
    "                    l = []\n",
    "            original = tb\n",
    "    return original\n",
    "def color(mat,image):\n",
    "    \n",
    "    ############################################################\n",
    "\n",
    "# For the color function, the points of the cluster and the \n",
    "# filtered image are passed through. In this function, the \n",
    "# average red, green, and blue pixel values are calculated\n",
    "# from the image inside of the cluster. If the average value\n",
    "# fits within a certain range, the string 'red' or 'green' is \n",
    "# returned. Otherwise, the function returns the string 'none'\n",
    "# The user is free to change the range of the BGR values that\n",
    "# determine whether the buoy is red or green.\n",
    "\n",
    "    sumred = 0\n",
    "    sumgrn = 0\n",
    "    sumblu = 0\n",
    "    for x in range(len(mat)):\n",
    "        sumred += image [mat[x][1]] [mat[x][0]] [2]\n",
    "        sumgrn += image [mat[x][1]] [mat[x][0]] [1]\n",
    "        sumblu += image [mat[x][1]] [mat[x][0]] [0]\n",
    "    if ((sumred/len(mat)) > 80 and (sumred/len(mat)) < 180 and (sumgrn/len(mat)) > 30 and (sumgrn/len(mat)) < 115  and (sumblu/len(mat)) > 30 and (sumblu/len(mat)) < 110):\n",
    "        return 'red'\n",
    "    if ((sumred/len(mat)) > 30 and (sumred/len(mat)) < 80 and (sumgrn/len(mat)) > 60 and (sumgrn/len(mat)) < 180  and (sumblu/len(mat)) > 50 and (sumblu/len(mat)) < 130):\n",
    "        return 'green'\n",
    "    else:\n",
    "        return 'none'\n",
    "def color_hsv(mat, image):\n",
    "    \n",
    "# The rectangle function's parameters are the array of coordinates\n",
    "# of the cluster, the color of the cluster, the filtered image,\n",
    "# and the original image. The boundingRect function applies\n",
    "# a non-rotated rectangle to the image points and returns four\n",
    "# values in an array, the x and y coordinates of the leftmost\n",
    "# corner and the width and height. These values are converted\n",
    "# to ints. The font is set to Hershey Simple for the text and\n",
    "# the tag is set to zero. The tag is useful in the classifica-\n",
    "# tion of the buoy. The first classification of the buoy is \n",
    "# the proportion of the width and height. If the height is\n",
    "# between 1.5 times the width and 3.5 times the width, the\n",
    "# cluster is considered a buoy. If the cluster is given a \n",
    "# 'red' or 'green' color, it would be classified as a 'red buoy'\n",
    "# or 'green buoy' respectively. Otherwise, it would simply be\n",
    "# classified as a buoy. If any of these three options occur, \n",
    "# the tag is set to 1. If the height is not in that range\n",
    "# mentioned above and the color is 'none', the cluster is\n",
    "# classified as noise. The last function rectangle makes a \n",
    "# rectangle over the original image. The original image is sent\n",
    "# back to the DBSCAN function.\n",
    "\n",
    "\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
    "    sumhue = 0\n",
    "    sumsat = 0\n",
    "    sumval = 0\n",
    "    mat_add = 0\n",
    "    for x in range(len(mat)):\n",
    "        if(image [mat[x][1]] [mat[x][0]] [2] > 5):\n",
    "            mat_add = mat_add+1\n",
    "            sumval += image [mat[x][1]] [mat[x][0]] [2]\n",
    "            sumsat += image [mat[x][1]] [mat[x][0]] [1]\n",
    "            sumhue += image [mat[x][1]] [mat[x][0]] [0]\n",
    "    if mat_add > 0:\n",
    "        sat = sumsat/mat_add\n",
    "        val = sumval/mat_add\n",
    "        hue = sumhue/mat_add\n",
    "        #return (hue, sat, val)\n",
    "        if (sat > 5 and val > 5 and (hue < 60 or hue >= 170)):\n",
    "            return 'red'\n",
    "        if (sat > 5 and val > 5 and (70 < hue < 90)):\n",
    "            return 'green'\n",
    "        else:\n",
    "            return (hue, sat, val)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def createLineIterator(P1, P2, img):\n",
    "# \"\"\"\n",
    "# Produces and array that consists of the coordinates and intensities of\n",
    "# each pixel in a line between two points\n",
    "\n",
    "# Parameters:\n",
    "#     -P1: a numpy array that consists of the coordinate of the first point (x,y)\n",
    "#     -P2: a numpy array that consists of the coordinate of the second point (x,y)\n",
    "#     -img: the image being processed\n",
    "\n",
    "# Returns:\n",
    "#     -it: a numpy array that consists of the coordinates and intensities of each\n",
    "#     pixel in the radii (shape: [numPixels, 3], row = [x,y,intensity])     \n",
    "# \"\"\"\n",
    "   #define local variables for readability\n",
    "    #print img.shape\n",
    "    image_height = img.shape[0]\n",
    "    image_width = img.shape[1]\n",
    "    P1X = P1[0]\n",
    "    P1Y = P1[1]\n",
    "    P2X = P2[0]\n",
    "    P2Y = P2[1]\n",
    "    \n",
    "   #difference and absolute difference between points\n",
    "   #used to calculate slope and relative location between points\n",
    "    dX = P2X - P1X\n",
    "    dY = P2Y - P1Y\n",
    "    dXa = np.abs(dX)\n",
    "    dYa = np.abs(dY)\n",
    "\n",
    "    #predefine numpy array for output based on distance between points\n",
    "    itbuffer = np.empty(shape=(np.maximum(dYa,dXa),3), dtype=np.int32)\n",
    "    itbuffer.fill(np.nan)\n",
    "\n",
    "   #Obtain coordinates along the line using a form of Bresenham's algorithm\n",
    "    negY = P1Y > P2Y\n",
    "    negX = P1X > P2X\n",
    "    if P1X == P2X: #vertical line segment\n",
    "        itbuffer[:,0] = P1X\n",
    "        if negY:\n",
    "            itbuffer[:,1] = np.arange(P1Y - 1,P1Y - dYa - 1,-1)\n",
    "        else:\n",
    "            itbuffer[:,1] = np.arange(P1Y+1,P1Y+dYa+1)              \n",
    "    elif P1Y == P2Y: #horizontal line segment\n",
    "        itbuffer[:,1] = P1Y\n",
    "        if negX:\n",
    "            itbuffer[:,0] = np.arange(P1X-1,P1X-dXa-1,-1)\n",
    "        else:\n",
    "            itbuffer[:,0] = np.arange(P1X+1,P1X+dXa+1)\n",
    "    else: #diagonal line segment\n",
    "        steepSlope = dYa > dXa\n",
    "        if steepSlope:\n",
    "            slope = dX.astype(np.float32)/dY.astype(np.float32)\n",
    "            if negY:\n",
    "                itbuffer[:,1] = np.arange(P1Y-1,P1Y-dYa-1,-1)\n",
    "            else:\n",
    "                itbuffer[:,1] = np.arange(P1Y+1,P1Y+dYa+1)\n",
    "            itbuffer[:,0] = (slope*(itbuffer[:,1]-P1Y)).astype(np.int) + P1X\n",
    "        else:\n",
    "            slope = dY.astype(np.float32)/dX.astype(np.float32)\n",
    "            if negX:\n",
    "                itbuffer[:,0] = np.arange(P1X-1,P1X-dXa-1,-1)\n",
    "            else:\n",
    "                itbuffer[:,0] = np.arange(P1X+1,P1X+dXa+1)\n",
    "            itbuffer[:,1] = (slope*(itbuffer[:,0]-P1X)).astype(np.int) + P1Y\n",
    "\n",
    "   #Remove points outside of image\n",
    "    colX = itbuffer[:,0]\n",
    "    colY = itbuffer[:,1]\n",
    "    itbuffer = itbuffer[(colX >= 0) & (colY >=0) & (colX<image_width) & (colY<image_height)]\n",
    "\n",
    "   #Get intensities from img ndarray\n",
    "    itbuffer[:,2] = img[itbuffer[:,1].astype(np.uint),itbuffer[:,0].astype(np.uint)]\n",
    "    return itbuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Initialization Stuff\n",
    "\n",
    "rospy.init_node('liveproc')\n",
    "listener = tf.TransformListener()\n",
    "listener.waitForTransform(\"/odom\", \"/front_left_camera_link\", rospy.Time(), rospy.Duration(2.0))\n",
    "\n",
    "occ_map = None\n",
    "map_resolution = 0.5\n",
    "origin = None\n",
    "robot_x = 0\n",
    "robot_y = 0\n",
    "map_width = 0\n",
    "map_height = 0\n",
    "camera_range = 75/map_resolution\n",
    "overlay = False\n",
    "display_robot_yaw = False\n",
    "display_rect = True\n",
    "display_map = True\n",
    "display_info = False\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0,
     39
    ]
   },
   "outputs": [],
   "source": [
    "def rectangle(mat,color,image,original):\n",
    "    \n",
    "    global bearings\n",
    "    global overlay\n",
    "    global occ_map\n",
    "    global tags\n",
    "    global display_info\n",
    "    \n",
    "    rect = cv.boundingRect(mat)\n",
    "    min_rect = cv.minAreaRect(mat)\n",
    "\n",
    "    height = rect[3]\n",
    "    width = rect[2]\n",
    "    x = rect[0]\n",
    "    x = np.int0(x)\n",
    "    y = rect[1] \n",
    "    y = np.int0(y)\n",
    "    font = cv.FONT_HERSHEY_SIMPLEX\n",
    "    tag = 0\n",
    "    if overlay:\n",
    "        if (width < height and 4*width > height and width*height > 45):\n",
    "            if(color =='green'):\n",
    "                tag = 2\n",
    "                cv.putText(original,color+' buoy',(np.int0(x-width/2),np.int0(y-height/2.5)), font, 0.5,(0,128,0),2,cv.LINE_AA)\n",
    "                tags.append(tag)\n",
    "            elif(color =='red'):\n",
    "                tag = 3\n",
    "                cv.putText(original,color+' buoy',(np.int0(x-width/2),np.int0(y-height/2.5)), font, 0.5,(0,0,128),2,cv.LINE_AA)\n",
    "                tags.append(tag)\n",
    "            else:\n",
    "                tag = 1\n",
    "                cv.putText(original,'buoy',(np.int0(x-width/2),np.int0(y-height/2.5)), font, 0.5,(255,255,255),2,cv.LINE_AA)\n",
    "                tags.append(tag)\n",
    "            cv.rectangle(original,(x,y),(x+width,y+height),(255,0,255),2)\n",
    "            bearing = (min_rect[0][0]-640.0)/1280.0*80.0\n",
    "            bearings.append(bearing)\n",
    "            if display_info and occ_map.header.seq % 5 == 0:\n",
    "                print bearings\n",
    "                print tags\n",
    "        if(tag == 0):\n",
    "            image[y:y+height][x:x+width]=[0,0,0]\n",
    "        return original\n",
    "    else:\n",
    "        if (width < height and 4*width > height and width*height > 45):\n",
    "            if(color =='green'):\n",
    "                tag = 2\n",
    "                cv.putText(image,color+' buoy',(np.int0(x-width/2),np.int0(y-height/2.5)), font, 0.5,(255,255,255),2,cv.LINE_AA)\n",
    "                tags.append(tag)\n",
    "            elif(color =='red'):\n",
    "                tag = 3\n",
    "                cv.putText(image,color+' buoy',(np.int0(x-width/2),np.int0(y-height/2.5)), font, 0.5,(255,255,255),2,cv.LINE_AA)\n",
    "                tags.append(tag)\n",
    "            else:\n",
    "                tag = 1\n",
    "                cv.putText(image,'buoy',(np.int0(x-width/2),np.int0(y-height/2.5)), font, 0.5,(255,255,255),2,cv.LINE_AA)\n",
    "                tags.append(tag)\n",
    "            cv.rectangle(image,(x,y),(x+width,y+height),(255,0,255),2)\n",
    "            bearing = (min_rect[0][0]-640.0)/1280.0*80.0\n",
    "            bearings.append(bearing)\n",
    "            if display_info and occ_map.header.seq % 5 == 0:\n",
    "                print bearings\n",
    "                print tags\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_mapnbot_info(trans,robot_yaw):\n",
    "\n",
    "    global map_resolution\n",
    "    global robot_x\n",
    "    global robot_y\n",
    "    global map_width\n",
    "    global map_height\n",
    "    global origin\n",
    "    global occ_map\n",
    "    \n",
    "    map_array = occ_map.data\n",
    "\n",
    "    map_width = occ_map.info.width\n",
    "    map_height = occ_map.info.height\n",
    "    map_np = np.reshape(np.array(map_array),(map_height,map_width))\n",
    "    robot_x = (trans[0]-origin.x)/map_resolution\n",
    "    robot_y = (trans[1]-origin.y)/map_resolution\n",
    "    robot_yaw = (90 - robot_yaw)\n",
    "    while robot_yaw > 360:\n",
    "        robot_yaw = robot_yaw - 360\n",
    "    while robot_yaw < 0:\n",
    "        robot_yaw = robot_yaw + 360\n",
    "    \n",
    "    return map_np, robot_yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def disp_rect(rect):\n",
    "    cv.namedWindow(\"stereo/left/image_rect_color\",cv.WINDOW_NORMAL)\n",
    "    cv.imshow(\"stereo/left/image_rect_color\", rect)\n",
    "    cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def map_filter(trans, robot_yaw):\n",
    "    \n",
    "    global origin\n",
    "    global robot_x\n",
    "    global robot_y\n",
    "    global camera_range\n",
    "    global occ_map\n",
    "    global bearings\n",
    "    global display_robot_yaw\n",
    "    global tags\n",
    "    \n",
    "    map_np, robot_yaw = get_mapnbot_info(trans,robot_yaw) \n",
    "    \n",
    "##############################################################################\n",
    "# This is for visualization purposes.\n",
    "# Set to false if you don't want to display the robot_yaw\n",
    "# Delete it if it's irritating to look at\n",
    "    if display_robot_yaw and occ_map.header.seq % 5 == 0:\n",
    "        yaw_offset.append(0.0)\n",
    "        print \"Robot_yaw: \", robot_yaw\n",
    "        print \"Buoy yaw: \", buoy_yaw\n",
    "        print len(slices)\n",
    "##############################################################################\n",
    "    \n",
    "    slices = []\n",
    "    i = 0\n",
    "    while (i < len(bearings)):\n",
    "        buoy_yaw = robot_yaw + bearings[i]\n",
    "        if ((buoy_yaw) < 0):\n",
    "            buoy_yaw = buoy_yaw + 360\n",
    "        point_deltax = camera_range * math.sin(math.radians(buoy_yaw))\n",
    "        point_deltay = camera_range * math.cos(math.radians(buoy_yaw))\n",
    "        \n",
    "        point1 = np.array([round(robot_x), round(robot_y)])\n",
    "        point2 = np.array([round(robot_x+point_deltax), round(robot_y+point_deltay)])\n",
    "        sliced = createLineIterator(point1.astype(int),point2.astype(int),map_np)\n",
    "        slices.append(sliced)\n",
    "        \n",
    "        point3 = np.array([round(robot_x+1), round(robot_y)])\n",
    "        point4 = np.array([round(robot_x+point_deltax+1), round(robot_y+point_deltay)])\n",
    "        sliced = createLineIterator(point3.astype(int),point4.astype(int),map_np)\n",
    "        slices.append(sliced)\n",
    "        \n",
    "        point5 = np.array([round(robot_x-1), round(robot_y)])\n",
    "        point6 = np.array([round(robot_x+point_deltax-1), round(robot_y+point_deltay)])\n",
    "        sliced = createLineIterator(point5.astype(int),point6.astype(int),map_np)\n",
    "        slices.append(sliced)\n",
    "        i+=1\n",
    "    \n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def draw_background_objects(map_img,map_np):\n",
    "    \n",
    "    global origin\n",
    "    global robot_x\n",
    "    global robot_y\n",
    "    \n",
    "    o_x = (-origin.x)/map_resolution\n",
    "    o_y = (-origin.y)/map_resolution\n",
    "# Color Assignment Section\n",
    "    map_img[map_np == -1] = [255,255,255]    \n",
    "    map_img[map_np == 0] = [255,255,255]\n",
    "    map_img[map_np == 100] = [0,0,0]\n",
    "    origin_color = [0,0,255]\n",
    "    robot_color = [0,0,255]\n",
    "# Origin (Drawn as a cross)\n",
    "\n",
    "    map_img[int(o_y)+0][int(o_x)+0] = origin_color\n",
    "    map_img[int(o_y)+0][int(o_x)+1] = origin_color\n",
    "    map_img[int(o_y)+0][int(o_x)+2] = origin_color\n",
    "    map_img[int(o_y)+1][int(o_x)+0] = origin_color\n",
    "    map_img[int(o_y)+2][int(o_x)+0] = origin_color\n",
    "    if (-origin.x) != 0:\n",
    "        map_img[int(o_y)+0][int(o_x)-1] = origin_color\n",
    "        map_img[int(o_y)+0][int(o_x)-2] = origin_color\n",
    "    if (-origin.y) != 0:\n",
    "        map_img[int(o_y)-1][int(o_x)+0] = origin_color\n",
    "        map_img[int(o_y)-2][int(o_x)+0] = origin_color\n",
    "# Robot (Drawn as a square)\n",
    "    map_img[int(robot_y)+0][int(robot_x)+0] = robot_color\n",
    "    map_img[int(robot_y)+0][int(robot_x)+2] = robot_color\n",
    "    map_img[int(robot_y)+1][int(robot_x)+2] = robot_color\n",
    "    map_img[int(robot_y)-1][int(robot_x)+2] = robot_color\n",
    "    map_img[int(robot_y)+0][int(robot_x)-2] = robot_color\n",
    "    map_img[int(robot_y)+1][int(robot_x)-2] = robot_color\n",
    "    map_img[int(robot_y)-1][int(robot_x)-2] = robot_color\n",
    "    map_img[int(robot_y)+2][int(robot_x)+0] = robot_color\n",
    "    map_img[int(robot_y)+2][int(robot_x)+1] = robot_color\n",
    "    map_img[int(robot_y)+2][int(robot_x)-1] = robot_color\n",
    "    map_img[int(robot_y)-2][int(robot_x)+0] = robot_color\n",
    "    map_img[int(robot_y)-2][int(robot_x)+1] = robot_color\n",
    "    map_img[int(robot_y)-2][int(robot_x)-1] = robot_color\n",
    "    \n",
    "    return map_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def draw_ray(map_img,slices):\n",
    "    \n",
    "    global display_robot_yaw\n",
    "    global bearings\n",
    "    global tags\n",
    "    \n",
    "    slices_size = len(slices)\n",
    "    \n",
    "    if not(display_robot_yaw):\n",
    "        for i in range(int(slices_size)):\n",
    "            try:\n",
    "                found = False\n",
    "                arr = slices[i]\n",
    "                for ray in arr:\n",
    "                    #print slice\n",
    "                    if not found and (ray[2] == -1 or ray[2] == 0):\n",
    "                        map_img[ray[1]][ray[0]] = [255,0,0]\n",
    "                    elif ray[2] == 100:\n",
    "                        if tags[i//3] == 2:\n",
    "                            map_img[ray[1]][ray[0]]=[0,255,0]\n",
    "                            found = True\n",
    "                        if tags[i//3] == 3:\n",
    "                            map_img[ray[1]][ray[0]]=[0,0,255]\n",
    "                            found = True\n",
    "            except Exception as ex:\n",
    "                print ex\n",
    "                print slices[i]\n",
    "                print\n",
    "    else:\n",
    "        for arr in slices[-1]:\n",
    "            map_img[arr[1]][arr[0]] = [0,255,0]\n",
    "    return map_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_map(slices):\n",
    "    \n",
    "    global camera_range\n",
    "    global origin\n",
    "    global robot_x\n",
    "    global robot_y\n",
    "    global map_width\n",
    "    global map_height\n",
    "    global occ_map\n",
    "    \n",
    "    map_np = np.reshape(np.array(occ_map.data),(map_height,map_width))\n",
    "\n",
    "    map_img = np.zeros((map_height, map_width, 3))\n",
    "    \n",
    "    map_img = draw_background_objects(map_img,map_np)\n",
    "    \n",
    "    map_img = draw_ray(map_img,slices)\n",
    "    \n",
    "    return map_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def disp_map(map_img):\n",
    "\n",
    "    map_img_i = np.zeros((map_width, map_height, 3))\n",
    "    \n",
    "    x=0\n",
    "    y=0\n",
    "    \n",
    "    for x in range(map_width):\n",
    "        for y in range(map_height):\n",
    "            map_img_i[x][y] = map_img[y][x]\n",
    "\n",
    "    cv.namedWindow(\"map_inverted\",cv.WINDOW_NORMAL)\n",
    "    cv.imshow(\"map_inverted\", map_img_i)\n",
    "    cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0,
     21,
     23,
     25,
     27,
     29,
     31
    ]
   },
   "outputs": [],
   "source": [
    "def callback(rect):\n",
    "    \n",
    "    global occ_map\n",
    "    global origin\n",
    "    global bearings\n",
    "    global listener \n",
    "    global display_rect\n",
    "    global display_map\n",
    "    global tags\n",
    "\n",
    "    origin = occ_map.info.origin.position\n",
    "    rect = transform(rect)\n",
    "        \n",
    "    if not rospy.is_shutdown():       \n",
    "        try:\n",
    "            now = rospy.Time.now()\n",
    "            listener.waitForTransform(\"/odom\", \"/base_link\", now, rospy.Duration(2.0))\n",
    "            (trans,rot) = listener.lookupTransform(\"/odom\", \"/base_link\", now)\n",
    "            euler = tf.transformations.euler_from_quaternion(rot)\n",
    "            pixel_lines = map_filter(trans, math.degrees(euler[2]))\n",
    "            map_image = get_map(pixel_lines)\n",
    "            if display_rect == True:\n",
    "                disp_rect(rect)\n",
    "            if display_map == True:\n",
    "                disp_map(map_image)\n",
    "        except tf.LookupException as l:\n",
    "            print l\n",
    "        except tf.ConnectivityException as c:\n",
    "            print c\n",
    "        except tf.ExtrapolationException as e:\n",
    "            print e\n",
    "        except Exception as ex:\n",
    "            print ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def map_callback(p_map):\n",
    "    \n",
    "    global occ_map\n",
    "    \n",
    "    occ_map = p_map    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot reshape array of size 260834 into shape (594,434)\n",
      "cannot reshape array of size 266200 into shape (605,434)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    proj_map = rospy.Subscriber(\"projected_map\", Map, map_callback)\n",
    "    rect = rospy.Subscriber(\"stereo/left/image_rect_color\", Image, callback)\n",
    "    rospy.spin()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
